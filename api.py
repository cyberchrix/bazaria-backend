# api.py

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import os
import uvicorn
import logging
import traceback
from datetime import datetime

# Import de notre syst√®me de recherche
from hybrid_search import HybridSearchAPI

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('api.log')
    ]
)
logger = logging.getLogger(__name__)

# Configuration
# OPENAI_API_KEY doit √™tre d√©finie comme variable d'environnement

# Mod√®les Pydantic
class SearchRequest(BaseModel):
    query: str
    limit: Optional[int] = 10

class SearchResult(BaseModel):
    id: str
    title: str
    description: str
    price: float
    location: str
    match_type: str
    score: float

class SearchResponse(BaseModel):
    query: str
    total_results: int
    text_results: int
    semantic_results: int
    results: List[SearchResult]

class HealthResponse(BaseModel):
    status: str
    message: str

# Initialisation de l'API
app = FastAPI(
    title="Bazaria Search API",
    description="API de recherche hybride pour les annonces Bazaria",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS pour Flutter
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En production, sp√©cifiez vos domaines
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Variable globale pour l'API de recherche
search_api = None

def get_search_api():
    """Dependency pour obtenir l'API de recherche"""
    global search_api
    if search_api is None:
        search_api = HybridSearchAPI(os.environ["OPENAI_API_KEY"])
    return search_api

@app.on_event("startup")
async def startup_event():
    """Initialisation au d√©marrage"""
    global search_api
    logger.info("üöÄ D√©marrage de l'API Bazaria Search...")
    
    # V√©rifier les variables d'environnement
    required_vars = [
        "OPENAI_API_KEY",
        "APPWRITE_ENDPOINT", 
        "APPWRITE_PROJECT_ID",
        "APPWRITE_API_KEY",
        "APPWRITE_DATABASE_ID",
        "APPWRITE_COLLECTION_ID"
    ]
    
    missing_vars = []
    for var in required_vars:
        if not os.environ.get(var):
            missing_vars.append(var)
            logger.error(f"‚ùå Variable d'environnement manquante: {var}")
    
    if missing_vars:
        logger.error(f"‚ùå Variables manquantes: {missing_vars}")
    else:
        logger.info("‚úÖ Toutes les variables d'environnement sont configur√©es")
    
    try:
        # V√©rifier et g√©n√©rer l'index si n√©cessaire
        from generate_index_on_startup import check_and_generate_index
        index_ok = check_and_generate_index()
        
        if not index_ok:
            logger.error("‚ùå Impossible de g√©n√©rer l'index FAISS")
            raise Exception("Index FAISS non disponible")
        
        search_api = HybridSearchAPI(os.environ["OPENAI_API_KEY"])
        logger.info("‚úÖ API de recherche initialis√©e avec succ√®s")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'initialisation de l'API: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise

@app.get("/", response_model=HealthResponse)
async def root():
    """Point d'entr√©e principal"""
    return HealthResponse(
        status="ok",
        message="Bazaria Search API - Utilisez /docs pour la documentation"
    )

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """V√©rification de l'√©tat de l'API"""
    logger.info("üîç Health check demand√©")
    try:
        api = get_search_api()
        
        # V√©rifications d√©taill√©es
        vectorstore_status = "‚úÖ" if api.vectorstore else "‚ùå"
        db_status = "‚úÖ" if api.db else "‚ùå"
        
        logger.info(f"Index FAISS: {vectorstore_status}")
        logger.info(f"Connexion Appwrite: {db_status}")
        
        if api.vectorstore and api.db:
            logger.info("‚úÖ API enti√®rement op√©rationnelle")
            return HealthResponse(
                status="healthy",
                message="API op√©rationnelle - Index FAISS et Appwrite connect√©s"
            )
        else:
            logger.warning("‚ö†Ô∏è API partiellement op√©rationnelle")
            return HealthResponse(
                status="warning",
                message="API partiellement op√©rationnelle - V√©rifiez les connexions"
            )
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du health check: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Erreur de sant√©: {str(e)}")

@app.post("/search", response_model=SearchResponse)
async def search_announcements(request: SearchRequest, api: HybridSearchAPI = Depends(get_search_api)):
    """
    Recherche d'annonces avec syst√®me hybride (complet mais plus lent)
    
    - **query**: Terme de recherche (ex: "villa", "Samsung", "V√©lo √©lectrique")
    - **limit**: Nombre maximum de r√©sultats (d√©faut: 10)
    """
    logger.info(f"üîç Recherche hybride demand√©e: '{request.query}' (limit: {request.limit})")
    
    try:
        if not request.query.strip():
            logger.warning("‚ùå Requ√™te vide rejet√©e")
            raise HTTPException(status_code=400, detail="La requ√™te ne peut pas √™tre vide")
        
        # Effectuer la recherche
        logger.info("üîç Ex√©cution de la recherche hybride...")
        results = api.hybrid_search(request.query, limit=request.limit)
        
        if "error" in results:
            logger.error(f"‚ùå Erreur lors de la recherche: {results['error']}")
            raise HTTPException(status_code=500, detail=results["error"])
        
        # Convertir les r√©sultats en format Pydantic
        search_results = []
        for result in results["results"]:
            search_results.append(SearchResult(
                id=result["id"],
                title=result["title"],
                description=result["description"],
                price=result["price"],
                location=result["location"],
                match_type=result["match_type"],
                score=result["score"]
            ))
        
        logger.info(f"‚úÖ Recherche hybride termin√©e: {results['total_results']} r√©sultats trouv√©s")
        logger.info(f"   - Correspondances textuelles: {results['text_results']}")
        logger.info(f"   - Correspondances s√©mantiques: {results['semantic_results']}")
        
        return SearchResponse(
            query=results["query"],
            total_results=results["total_results"],
            text_results=results["text_results"],
            semantic_results=results["semantic_results"],
            results=search_results
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur inattendue lors de la recherche: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la recherche: {str(e)}")

@app.post("/search/fast", response_model=SearchResponse)
async def search_announcements_fast(request: SearchRequest, api: HybridSearchAPI = Depends(get_search_api)):
    """
    Recherche rapide d'annonces (utilise uniquement l'index FAISS)
    
    - **query**: Terme de recherche (ex: "villa", "Samsung", "V√©lo √©lectrique")
    - **limit**: Nombre maximum de r√©sultats (d√©faut: 10)
    """
    logger.info(f"üöÄ Recherche rapide demand√©e: '{request.query}' (limit: {request.limit})")
    
    try:
        if not request.query.strip():
            logger.warning("‚ùå Requ√™te vide rejet√©e")
            raise HTTPException(status_code=400, detail="La requ√™te ne peut pas √™tre vide")
        
        # Effectuer la recherche rapide
        logger.info("üöÄ Ex√©cution de la recherche rapide...")
        
        # Utiliser directement l'index FAISS pour la recherche
        if not api.vectorstore:
            raise HTTPException(status_code=500, detail="Index FAISS non disponible")
        
        # Recherche s√©mantique dans FAISS
        results_with_scores = api.vectorstore.similarity_search_with_score(request.query, k=request.limit * 2)
        
        # Filtrer et formater les r√©sultats
        filtered_results = []
        for doc, score in results_with_scores:
            if score >= 0.2:  # Seuil de confiance ajust√© pour les scores s√©mantiques r√©els
                # Utiliser les m√©tadonn√©es directement de l'index FAISS
                metadata = doc.metadata
                if metadata and metadata.get('id'):
                    # Essayer de r√©cup√©rer les d√©tails depuis Appwrite
                    announcement_details = api._get_announcement_details(metadata.get('id'))
                    if announcement_details:
                        filtered_results.append({
                            'id': metadata.get('id'),
                            'title': announcement_details.get('title'),
                            'description': announcement_details.get('description'),
                            'price': announcement_details.get('price'),
                            'location': announcement_details.get('location'),
                            'match_type': 'semantic',
                            'score': score
                        })
                    else:
                        # Fallback : utiliser les m√©tadonn√©es de l'index
                        logger.warning(f"‚ö†Ô∏è Impossible de r√©cup√©rer les d√©tails pour {metadata.get('id')}, utilisation des m√©tadonn√©es de l'index")
                        filtered_results.append({
                            'id': metadata.get('id'),
                            'title': metadata.get('title', 'Titre non disponible'),
                            'description': metadata.get('description', 'Description non disponible'),
                            'price': metadata.get('price', 0.0),
                            'location': metadata.get('location', 'Localisation non disponible'),
                            'match_type': 'semantic',
                            'score': score
                        })
        
        # Trier par score et limiter
        filtered_results.sort(key=lambda x: x['score'], reverse=True)
        final_results = filtered_results[:request.limit]
        
        # Convertir les r√©sultats en format Pydantic
        search_results = []
        for result in final_results:
            search_results.append(SearchResult(
                id=result["id"],
                title=result["title"],
                description=result["description"],
                price=result["price"],
                location=result["location"],
                match_type=result["match_type"],
                score=result["score"]
            ))
        
        logger.info(f"‚úÖ Recherche rapide termin√©e: {len(final_results)} r√©sultats trouv√©s")
        
        return SearchResponse(
            query=request.query,
            total_results=len(final_results),
            text_results=0,
            semantic_results=len(final_results),
            results=search_results
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur inattendue lors de la recherche rapide: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la recherche rapide: {str(e)}")

@app.get("/search/{query}", response_model=SearchResponse)
async def search_announcements_get(
    query: str, 
    limit: Optional[int] = 10,
    api: HybridSearchAPI = Depends(get_search_api)
):
    """
    Recherche d'annonces via GET (pour tests rapides)
    
    - **query**: Terme de recherche dans l'URL
    - **limit**: Nombre maximum de r√©sultats (param√®tre query)
    """
    try:
        if not query.strip():
            raise HTTPException(status_code=400, detail="La requ√™te ne peut pas √™tre vide")
        
        # Effectuer la recherche
        results = api.hybrid_search(query, limit=limit)
        
        if "error" in results:
            raise HTTPException(status_code=500, detail=results["error"])
        
        # Convertir les r√©sultats en format Pydantic
        search_results = []
        for result in results["results"]:
            search_results.append(SearchResult(
                id=result["id"],
                title=result["title"],
                description=result["description"],
                price=result["price"],
                location=result["location"],
                match_type=result["match_type"],
                score=result["score"]
            ))
        
        return SearchResponse(
            query=results["query"],
            total_results=results["total_results"],
            text_results=results["text_results"],
            semantic_results=results["semantic_results"],
            results=search_results
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la recherche: {str(e)}")

@app.get("/stats")
async def get_stats(api: HybridSearchAPI = Depends(get_search_api)):
    """Statistiques de l'API"""
    try:
        if api.vectorstore:
            total_docs = len(api.vectorstore.index_to_docstore_id)
            return {
                "total_announcements": total_docs,
                "index_status": "loaded",
                "search_api_status": "operational"
            }
        else:
            return {
                "total_announcements": 0,
                "index_status": "not_loaded",
                "search_api_status": "error"
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la r√©cup√©ration des stats: {str(e)}")

@app.post("/admin/rebuild-index")
async def rebuild_index_endpoint():
    """Force la reconstruction compl√®te de l'index (admin only)"""
    try:
        logger.info("üîÑ Reconstruction forc√©e de l'index demand√©e...")
        
        from update_index import rebuild_index
        rebuild_index()
        
        logger.info("‚úÖ Index reconstruit avec succ√®s")
        return {"message": "Index reconstruit avec succ√®s", "status": "success"}
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la reconstruction: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la reconstruction: {str(e)}")

@app.post("/admin/update-index")
async def update_index_endpoint():
    """Met √† jour l'index avec les nouvelles annonces (admin only)"""
    try:
        logger.info("üîÑ Mise √† jour de l'index demand√©e...")
        
        from update_index import update_index
        result = update_index()
        
        if result.get("success"):
            logger.info(f"‚úÖ Index mis √† jour: {result.get('new_announcements', 0)} nouvelles annonces")
            return {
                "message": f"Index mis √† jour avec {result.get('new_announcements', 0)} nouvelles annonces",
                "status": "success",
                "new_announcements": result.get('new_announcements', 0)
            }
        else:
            logger.warning(f"‚ö†Ô∏è Mise √† jour partielle: {result.get('message', 'Erreur inconnue')}")
            return {
                "message": result.get('message', 'Erreur inconnue'),
                "status": "partial",
                "new_announcements": result.get('new_announcements', 0)
            }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la mise √† jour: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la mise √† jour: {str(e)}")

if __name__ == "__main__":
    # Configuration pour le d√©veloppement
    uvicorn.run(
        "api:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    ) 