# api.py - API unifi√©e pour local et production

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import os
import uvicorn
import logging
import traceback
from datetime import datetime

# Import de notre syst√®me de recherche
from hybrid_search import HybridSearchAPI
from appwrite.client import Client
from appwrite.services.databases import Databases
from appwrite.query import Query

# D√©tection de l'environnement
IS_LOCAL = os.environ.get("ENVIRONMENT", "production") == "local"

# Configuration du logging
if IS_LOCAL:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[logging.StreamHandler()]
    )
else:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('api.log')
        ]
    )
logger = logging.getLogger(__name__)

# Configuration
# OPENAI_API_KEY doit √™tre d√©finie comme variable d'environnement

# Mod√®les Pydantic
class SearchRequest(BaseModel):
    query: str
    limit: Optional[int] = 10

class SearchResult(BaseModel):
    id: str
    title: str
    description: str
    price: float
    location: str
    match_type: str
    score: float

class SearchResponse(BaseModel):
    query: str
    total_results: int
    text_results: int
    semantic_results: int
    
    results: List[SearchResult]

class HealthResponse(BaseModel):
    status: str
    message: str

# Initialisation de l'API
app = FastAPI(
    title="Bazaria Search API" + (" - Local" if IS_LOCAL else ""),
    description="API de recherche hybride pour les annonces Bazaria" + (" (Mode local)" if IS_LOCAL else ""),
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS pour Flutter
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En production, sp√©cifiez vos domaines
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Variable globale pour l'API de recherche
search_api = None

def get_search_api():
    """Dependency pour obtenir l'API de recherche"""
    global search_api
    if search_api is None:
        search_api = HybridSearchAPI(os.environ["OPENAI_API_KEY"])
    return search_api

@app.on_event("startup")
async def startup_event():
    """Initialisation au d√©marrage"""
    import os
    
    global search_api
    env_type = "LOCAL" if IS_LOCAL else "PRODUCTION"
    logger.info(f"üöÄ D√©marrage de l'API Bazaria Search ({env_type})...")
    
    # V√©rifier les variables d'environnement
    required_vars = [
        "OPENAI_API_KEY",
        "APPWRITE_ENDPOINT", 
        "APPWRITE_PROJECT_ID",
        "APPWRITE_API_KEY",
        "APPWRITE_DATABASE_ID",
        "APPWRITE_COLLECTION_ID"
    ]
    
    missing_vars = []
    for var in required_vars:
        if not os.environ.get(var):
            missing_vars.append(var)
            logger.error(f"‚ùå Variable d'environnement manquante: {var}")
    
    if missing_vars:
        logger.error(f"‚ùå Variables manquantes: {missing_vars}")
        if IS_LOCAL:
            logger.warning("‚ö†Ô∏è Mode local avec variables manquantes - certaines fonctionnalit√©s peuvent √™tre limit√©es")
    else:
        logger.info("‚úÖ Toutes les variables d'environnement sont configur√©es")
    
    try:
        # V√©rifier et g√©n√©rer l'index si n√©cessaire
        from generate_index_paginated import generate_index
        
        # V√©rifier si l'index existe
        if not os.path.exists("index_bazaria"):
            logger.info("üîç Index FAISS non trouv√©, g√©n√©ration...")
            generate_index()
            logger.info("‚úÖ Index FAISS g√©n√©r√© avec succ√®s")
        else:
            logger.info("‚úÖ Index FAISS trouv√©")
        
        index_ok = True
        
        search_api = HybridSearchAPI(os.environ["OPENAI_API_KEY"])
        logger.info("‚úÖ API de recherche initialis√©e avec succ√®s")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'initialisation de l'API: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        if IS_LOCAL:
            logger.warning("‚ö†Ô∏è Mode local - l'API continuera avec des fonctionnalit√©s limit√©es")
        else:
            raise

@app.get("/", response_model=HealthResponse)
async def root():
    """Point d'entr√©e principal"""
    env_type = "LOCAL" if IS_LOCAL else "PRODUCTION"
    return HealthResponse(
        status="ok",
        message=f"Bazaria Search API ({env_type}) - Utilisez /docs pour la documentation"
    )

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """V√©rification de l'√©tat de l'API"""
    logger.info("üîç Health check demand√©")
    try:
        api = get_search_api()
        
        # V√©rifications d√©taill√©es
        vectorstore_status = "‚úÖ" if api.vectorstore else "‚ùå"
        db_status = "‚úÖ" if api.db else "‚ùå"
        
        logger.info(f"Index FAISS: {vectorstore_status}")
        logger.info(f"Connexion Appwrite: {db_status}")
        
        if api.vectorstore and api.db:
            logger.info("‚úÖ API enti√®rement op√©rationnelle")
            env_type = "LOCAL" if IS_LOCAL else "PRODUCTION"
            return HealthResponse(
                status="healthy",
                message=f"API {env_type} op√©rationnelle - Index FAISS et Appwrite connect√©s"
            )
        else:
            logger.warning("‚ö†Ô∏è API partiellement op√©rationnelle")
            env_type = "LOCAL" if IS_LOCAL else "PRODUCTION"
            return HealthResponse(
                status="warning",
                message=f"API {env_type} partiellement op√©rationnelle - V√©rifiez les connexions"
            )
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du health check: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Erreur de sant√©: {str(e)}")

@app.post("/search/keyword", response_model=SearchResponse)
async def search_announcements_keyword(request: SearchRequest, api: HybridSearchAPI = Depends(get_search_api)):
    """
    Recherche par mots-cl√©s exacts (pour termes pr√©cis)
    
    - **query**: Mot-cl√© pr√©cis (ex: "villa", "Samsung", "V√©lo √©lectrique")
    - **limit**: Nombre maximum de r√©sultats (d√©faut: 10)
    """
    logger.info(f"üîç Recherche par mots-cl√©s demand√©e: '{request.query}' (limit: {request.limit})")
    
    try:
        if not request.query.strip():
            logger.warning("‚ùå Requ√™te vide rejet√©e")
            raise HTTPException(status_code=400, detail="La requ√™te ne peut pas √™tre vide")
        
        # R√©cup√©rer toutes les annonces pour la recherche textuelle directe
        logger.info("üì• R√©cup√©ration des annonces depuis Appwrite...")
        
        # R√©cup√©rer toutes les annonces avec pagination
        all_announcements = []
        offset = 0
        limit_per_page = 25
        
        while True:
            try:
                response = api.db.list_documents(
                    database_id=os.environ.get("APPWRITE_DATABASE_ID"),
                    collection_id=os.environ.get("APPWRITE_COLLECTION_ID"),
                    queries=[Query.offset(offset), Query.limit(limit_per_page)]
                )
                
                documents = response.get('documents', [])
                if not documents:
                    break
                
                all_announcements.extend(documents)
                offset += limit_per_page
                
                if len(documents) < limit_per_page:
                    break
                    
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des annonces: {e}")
                break
        
        logger.info(f"üìä Total d'annonces r√©cup√©r√©es: {len(all_announcements)}")
        
        # Recherche textuelle directe (sans FAISS, sans OpenAI)
        logger.info("üîç Ex√©cution de la recherche textuelle directe...")
        query_lower = request.query.lower()
        text_results = []
        
        for announcement in all_announcements:
            # Chercher dans le titre et la description
            title = announcement.get('title', '').lower()
            description = announcement.get('description', '').lower()
            
            # V√©rifier si la requ√™te appara√Æt dans le titre ou la description
            if query_lower in title or query_lower in description:
                text_results.append({
                    'id': announcement.get('$id'),
                    'title': announcement.get('title'),
                    'description': announcement.get('description'),
                    'price': announcement.get('price', 0.0),
                    'location': announcement.get('location', ''),
                    'match_type': 'text',
                    'score': 1.0  # Score parfait pour correspondance textuelle
                })
        
        # Limiter les r√©sultats
        final_results = text_results[:request.limit]
        
        # Convertir les r√©sultats en format Pydantic
        search_results = []
        for result in final_results:
            search_results.append(SearchResult(
                id=result["id"],
                title=result["title"],
                description=result["description"],
                price=result["price"],
                location=result["location"],
                match_type=result["match_type"],
                score=result["score"]
            ))
        
        logger.info(f"‚úÖ Recherche par mots-cl√©s termin√©e: {len(final_results)} r√©sultats trouv√©s")
        logger.info(f"   - Correspondances textuelles: {len(final_results)}")
        logger.info(f"   - Correspondances s√©mantiques: 0")
        
        return SearchResponse(
            query=request.query,
            total_results=len(final_results),
            text_results=len(final_results),
            semantic_results=0,
            results=search_results
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur inattendue lors de la recherche par mots-cl√©s: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la recherche par mots-cl√©s: {str(e)}")

@app.post("/search/semantic", response_model=SearchResponse)
async def search_announcements_semantic(request: SearchRequest, api: HybridSearchAPI = Depends(get_search_api)):
    """
    Recherche s√©mantique pure (pour concepts, intentions, synonymes)
    
    - **query**: Concept ou intention (ex: "pour me d√©placer", "moderne et √©l√©gant")
    - **limit**: Nombre maximum de r√©sultats (d√©faut: 10)
    """
    logger.info(f"üß† Recherche s√©mantique demand√©e: '{request.query}' (limit: {request.limit})")
    
    try:
        if not request.query.strip():
            logger.warning("‚ùå Requ√™te vide rejet√©e")
            raise HTTPException(status_code=400, detail="La requ√™te ne peut pas √™tre vide")
        
        # Utiliser directement l'index FAISS pour la recherche s√©mantique
        if not api.vectorstore:
            raise HTTPException(status_code=500, detail="Index FAISS non disponible")
        
        # Recherche s√©mantique dans FAISS
        results_with_scores = api.vectorstore.similarity_search_with_score(request.query, k=request.limit * 2)
        
        # Filtrer et formater les r√©sultats
        filtered_results = []
        for doc, score in results_with_scores:
            if score >= 1.0:  # Seuil pour la recherche s√©mantique (plus le score est √©lev√©, plus c'est pertinent avec le nouveau mod√®le)
                # Utiliser les m√©tadonn√©es directement de l'index FAISS
                metadata = doc.metadata
                if metadata and metadata.get('id'):
                    # Essayer de r√©cup√©rer les d√©tails depuis Appwrite
                    announcement_details = api._get_announcement_details(metadata.get('id'))
                    if announcement_details:
                        filtered_results.append({
                            'id': metadata.get('id'),
                            'title': announcement_details.get('title'),
                            'description': announcement_details.get('description'),
                            'price': announcement_details.get('price'),
                            'location': announcement_details.get('location'),
                            'match_type': 'semantic',
                            'score': score
                        })
                    else:
                        # Fallback : utiliser les m√©tadonn√©es de l'index
                        filtered_results.append({
                            'id': metadata.get('id'),
                            'title': metadata.get('title', 'Titre non disponible'),
                            'description': metadata.get('description', 'Description non disponible'),
                            'price': metadata.get('price', 0.0),
                            'location': metadata.get('location', 'Localisation non disponible'),
                            'match_type': 'semantic',
                            'score': score
                        })
        
        # Limiter le nombre de r√©sultats
        filtered_results = filtered_results[:request.limit]
        
        # Convertir les r√©sultats en format Pydantic
        search_results = []
        for result in filtered_results:
            search_results.append(SearchResult(
                id=result["id"],
                title=result["title"],
                description=result["description"],
                price=result["price"],
                location=result["location"],
                match_type=result["match_type"],
                score=result["score"]
            ))
        
        logger.info(f"‚úÖ Recherche s√©mantique termin√©e: {len(filtered_results)} r√©sultats trouv√©s")
        
        return SearchResponse(
            query=request.query,
            total_results=len(filtered_results),
            text_results=0,  # Pas de r√©sultats textuels en recherche s√©mantique pure
            semantic_results=len(filtered_results),
            results=search_results
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur inattendue lors de la recherche s√©mantique: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la recherche s√©mantique: {str(e)}")


@app.post("/search/category", response_model=SearchResponse)
async def search_announcements_by_category(request: SearchRequest, api: HybridSearchAPI = Depends(get_search_api)):
    """
    Recherche par cat√©gorie (V√©hicules, Immobilier, √âlectronique, Mobilier, etc.)
    
    - **query**: Cat√©gorie ou sous-cat√©gorie (ex: "V√©hicules", "Immobilier", "√âlectronique")
    - **limit**: Nombre maximum de r√©sultats (d√©faut: 10)
    """
    logger.info(f"üè∑Ô∏è  Recherche par cat√©gorie demand√©e: '{request.query}' (limit: {request.limit})")
    
    try:
        if not request.query.strip():
            logger.warning("‚ùå Requ√™te vide rejet√©e")
            raise HTTPException(status_code=400, detail="La requ√™te ne peut pas √™tre vide")
        
        # Utiliser l'index FAISS pour la recherche par cat√©gorie
        if not api.vectorstore:
            raise HTTPException(status_code=500, detail="Index FAISS non disponible")
        
        # Recherche s√©mantique dans FAISS avec focus sur la cat√©gorie
        results_with_scores = api.vectorstore.similarity_search_with_score(request.query, k=request.limit * 3)
        
        # Filtrer par cat√©gorie et formater les r√©sultats
        filtered_results = []
        category_lower = request.query.lower()
        
        for doc, score in results_with_scores:
            # V√©rifier si la cat√©gorie correspond
            metadata = doc.metadata
            doc_category = metadata.get('category', '').lower()
            
            # Correspondance exacte ou partielle de cat√©gorie
            if (category_lower in doc_category or 
                doc_category in category_lower or
                any(word in doc_category for word in category_lower.split())):
                
                if score >= 0.25:  # Seuil plus bas pour la recherche par cat√©gorie
                    # R√©cup√©rer les d√©tails depuis Appwrite
                    announcement_details = api._get_announcement_details(metadata.get('id'))
                    if announcement_details:
                        filtered_results.append({
                            'id': metadata.get('id'),
                            'title': announcement_details.get('title'),
                            'description': announcement_details.get('description'),
                            'price': announcement_details.get('price'),
                            'location': announcement_details.get('location'),
                            'category': metadata.get('category', 'Non class√©'),
                            'match_type': 'category',
                            'score': score
                        })
        
        # Limiter le nombre de r√©sultats
        filtered_results = filtered_results[:request.limit]
        
        # Convertir les r√©sultats en format Pydantic
        search_results = []
        for result in filtered_results:
            search_results.append(SearchResult(
                id=result["id"],
                title=result["title"],
                description=result["description"],
                price=result["price"],
                location=result["location"],
                match_type=result["match_type"],
                score=result["score"]
            ))
        
        logger.info(f"‚úÖ Recherche par cat√©gorie termin√©e: {len(filtered_results)} r√©sultats trouv√©s")
        logger.info(f"   - Cat√©gorie recherch√©e: {request.query}")
        
        return SearchResponse(
            query=request.query,
            total_results=len(filtered_results),
            text_results=0,
            semantic_results=len(filtered_results),
            results=search_results
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur inattendue lors de la recherche par cat√©gorie: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la recherche par cat√©gorie: {str(e)}")


@app.get("/categories")
async def get_categories(api: HybridSearchAPI = Depends(get_search_api)):
    """
    Liste toutes les cat√©gories disponibles dans l'index
    """
    logger.info("üìã Demande de liste des cat√©gories...")
    
    try:
        if not api.vectorstore:
            raise HTTPException(status_code=500, detail="Index FAISS non disponible")
        
        # R√©cup√©rer toutes les cat√©gories depuis l'index
        categories_count = {}
        total_docs = len(api.vectorstore.index_to_docstore_id)
        
        # Parcourir tous les documents pour compter les cat√©gories
        for doc_id in api.vectorstore.index_to_docstore_id.values():
            doc = api.vectorstore.docstore._dict.get(doc_id)
            if doc and doc.metadata:
                category = doc.metadata.get('category', 'Non class√©')
                categories_count[category] = categories_count.get(category, 0) + 1
        
        # Trier par nombre d'annonces d√©croissant
        sorted_categories = sorted(categories_count.items(), key=lambda x: x[1], reverse=True)
        
        logger.info(f"‚úÖ Cat√©gories r√©cup√©r√©es: {len(categories_count)} cat√©gories trouv√©es")
        
        return {
            "total_announcements": total_docs,
            "categories": [
                {
                    "name": category,
                    "count": count,
                    "percentage": round((count / total_docs) * 100, 1)
                }
                for category, count in sorted_categories
            ]
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des cat√©gories: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la r√©cup√©ration des cat√©gories: {str(e)}")


@app.get("/stats")
async def get_stats(api: HybridSearchAPI = Depends(get_search_api)):
    """Statistiques de l'API"""
    try:
        if api.vectorstore:
            total_docs = len(api.vectorstore.index_to_docstore_id)
            return {
                "total_announcements": total_docs,
                "index_status": "loaded",
                "search_api_status": "operational"
            }
        else:
            return {
                "total_announcements": 0,
                "index_status": "not_loaded",
                "search_api_status": "error"
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la r√©cup√©ration des stats: {str(e)}")

@app.post("/admin/rebuild-index")
async def rebuild_index_endpoint():
    """Force la reconstruction compl√®te de l'index (admin only)"""
    try:
        logger.info("üîÑ Reconstruction forc√©e de l'index demand√©e...")
        
        from generate_index_paginated import generate_index
        generate_index()
        
        logger.info("‚úÖ Index reconstruit avec succ√®s")
        return {"message": "Index reconstruit avec succ√®s", "status": "success"}
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la reconstruction: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la reconstruction: {str(e)}")

@app.post("/admin/update-index")
async def update_index_endpoint():
    """Met √† jour l'index avec les nouvelles annonces (admin only)"""
    try:
        logger.info("üîÑ Mise √† jour de l'index demand√©e...")
        
        from generate_index_paginated import generate_index
        generate_index()
        
        logger.info("‚úÖ Index mis √† jour avec succ√®s")
        return {
            "message": "Index mis √† jour avec succ√®s",
            "status": "success",
            "new_announcements": 0
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la mise √† jour: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la mise √† jour: {str(e)}")

@app.get("/admin/index-content")
async def get_index_content(api: HybridSearchAPI = Depends(get_search_api)):
    """Liste le contenu de l'index FAISS (admin only)"""
    try:
        logger.info("üìã Demande de contenu de l'index...")
        
        if not api.vectorstore:
            raise HTTPException(status_code=500, detail="Index FAISS non disponible")
        
        # R√©cup√©rer le contenu de l'index
        index_content = []
        
        # Parcourir tous les documents de l'index
        for doc_id, doc in api.vectorstore.index_to_docstore_id.items():
            try:
                # R√©cup√©rer le document
                document = api.vectorstore.docstore.search(doc)
                
                if document:
                    # Extraire les m√©tadonn√©es
                    metadata = document.metadata
                    content = document.page_content[:200] + "..." if len(document.page_content) > 200 else document.page_content
                    
                    index_content.append({
                        "id": metadata.get('id', 'N/A'),
                        "title": metadata.get('title', 'Titre non disponible'),
                        "description": metadata.get('description', 'Description non disponible'),
                        "price": metadata.get('price', 0.0),
                        "location": metadata.get('location', 'Localisation non disponible'),
                        "content_preview": content,
                        "doc_id": doc_id
                    })
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration du document {doc_id}: {e}")
                continue
        
        # Trier par titre pour une meilleure lisibilit√©
        index_content.sort(key=lambda x: x['title'])
        
        logger.info(f"‚úÖ Contenu de l'index r√©cup√©r√©: {len(index_content)} documents")
        
        return {
            "total_documents": len(index_content),
            "index_status": "loaded",
            "documents": index_content
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration du contenu: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la r√©cup√©ration du contenu: {str(e)}")

@app.get("/admin/test-scores/{query}")
async def test_scores(query: str, api: HybridSearchAPI = Depends(get_search_api)):
    """Teste tous les scores pour une requ√™te sans filtre (admin only)"""
    try:
        logger.info(f"üîç Test des scores pour '{query}'...")
        
        if not api.vectorstore:
            raise HTTPException(status_code=500, detail="Index FAISS non disponible")
        
        # Recherche s√©mantique dans FAISS sans filtre
        results_with_scores = api.vectorstore.similarity_search_with_score(query, k=50)
        
        # Formater tous les r√©sultats avec leurs scores
        all_results = []
        for doc, score in results_with_scores:
            try:
                metadata = doc.metadata
                all_results.append({
                    'id': metadata.get('id', 'N/A'),
                    'title': metadata.get('title', 'Titre non disponible'),
                    'description': metadata.get('description', 'Description non disponible'),
                    'price': metadata.get('price', 0.0),
                    'location': metadata.get('location', 'Localisation non disponible'),
                    'score': float(score) if score is not None else 0.0
                })
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur lors du traitement du document: {e}")
                continue
        
        # Trier par score d√©croissant
        all_results.sort(key=lambda x: x['score'], reverse=True)
        
        logger.info(f"‚úÖ Test des scores termin√©: {len(all_results)} r√©sultats")
        
        return {
            "query": query,
            "total_results": len(all_results),
            "results": all_results
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du test des scores: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur lors du test des scores: {str(e)}")

@app.get("/admin/force-new-format")
async def force_new_format():
    """Force l'utilisation du nouveau format (admin only)"""
    try:
        logger.info("üîÑ For√ßage du nouveau format...")
        
        # Forcer la mise √† jour avec le nouveau format
        from update_index import update_index
        result = update_index()
        
        if result.get("success"):
            logger.info(f"‚úÖ Nouveau format appliqu√©: {result.get('new_announcements', 0)} annonces")
            return {
                "message": f"Nouveau format appliqu√© avec {result.get('new_announcements', 0)} annonces",
                "status": "success",
                "new_announcements": result.get('new_announcements', 0)
            }
        else:
            logger.warning(f"‚ö†Ô∏è √âchec de l'application du nouveau format: {result.get('message', 'Erreur inconnue')}")
            return {
                "message": result.get('message', 'Erreur inconnue'),
                "status": "error",
                "new_announcements": 0
            }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du for√ßage du nouveau format: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur lors du for√ßage du nouveau format: {str(e)}")

@app.get("/admin/cache-stats")
async def get_cache_stats(api: HybridSearchAPI = Depends(get_search_api)):
    """R√©cup√®re les statistiques des caches (admin only)"""
    try:
        logger.info("üìä R√©cup√©ration des statistiques des caches...")
        
        embedding_stats = api.embedding_cache.get_stats()
        result_stats = api.result_cache.get_stats()
        
        logger.info(f"‚úÖ Statistiques des caches r√©cup√©r√©es")
        
        return {
            "embedding_cache": {
                "total_entries": embedding_stats['total_entries'],
                "cache_file": embedding_stats['cache_file'],
                "duration_hours": embedding_stats['duration_hours']
            },
            "result_cache": {
                "total_entries": result_stats['total_entries'],
                "cache_file": result_stats['cache_file'],
                "duration_hours": result_stats['duration_hours']
            }
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration stats cache: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")

@app.post("/admin/clear-cache")
async def clear_cache(api: HybridSearchAPI = Depends(get_search_api)):
    """Vide tous les caches (admin only)"""
    try:
        logger.info("üóëÔ∏è Vidage de tous les caches...")
        
        # Vider le cache des embeddings
        api.embedding_cache.cache = {}
        api.embedding_cache._save_cache()
        
        # Vider le cache des r√©sultats
        api.result_cache.cache = {}
        api.result_cache._save_cache()
        
        logger.info("‚úÖ Tous les caches vid√©s avec succ√®s")
        return {"message": "Tous les caches vid√©s avec succ√®s", "status": "success"}
        
    except Exception as e:
        logger.error(f"‚ùå Erreur vidage cache: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")

if __name__ == "__main__":
    # Configuration pour le d√©veloppement local
    print("üöÄ D√©marrage de l'API en mode LOCAL")
    print("üìç URL: http://localhost:8000")
    print("üìö Documentation: http://localhost:8000/docs")
    print("‚èπÔ∏è  Pour arr√™ter: Ctrl+C")
    print()
    
    uvicorn.run(
        "api:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    ) 